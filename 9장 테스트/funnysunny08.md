## 9.1 테스트 유형

<img width="802" height="384" alt="Image" src="https://github.com/user-attachments/assets/48476664-dd33-4c5e-83b8-bb90a087090d" />

- 기술 대면 테스트: 처음부터 개발자가 시스템을 구축하는 데 도움을 주는 테스트
- 비즈니스 대면 테스트: 비기술 이해관게자가 시스템의 작동 방식을 이해나는 것을 돕는 테스트

## 9.2 테스트 범위

<img width="533" height="438" alt="Image" src="https://github.com/user-attachments/assets/96f05a8c-dcf1-4caa-972a-c04796b60792" />

- 피미드의 중간으로 올라갈수록 테스트의 범위는 증가하고 테스트 중인 기능이 작동한다는 확신도 커진다.
    - 테스트 실행 시간과 피드백 주기 시간은 증가하며, 실패 원인 파악이 어려워진다.
- 더  작은 범위의 테스트는 더 잘 격리돼 고장을 이해하고 수정하기가 더 쉽지만, 시스템 전체가 제대로 작동한다고 확신할 순 없다.

### 9.2.1 단위 테스트

- 단일 함수 또는 메서드 호출을 테스트한다.
    - 외부 파일 사용이나 네트워크 연결 제한
- 기능이 정상적으로 작동하는지에 대한 매우 빠른 피드백을 제공
    - 대부분의 버그를 이 단계에서 잡는 것이 목표

### 9.2.2 서비스 테스트

- 개별 서비스 기능이 기대대로 동작하는지 확인
- 테스트 실패 원인은 해당 서비스로 한정되도록 설계
- 외부 협력 시스템은 격리하거나 제거하는 방식 권장
    - DB·네트워크 연결을 사용할 수도 있음 → 느려질 수 있음
- 단위 테스트보다 원인 파악이 어려워질 수 있음
    - 하지만 엔드투엔드 테스트보다는 안정적

### 9.2.3 엔드투엔드 테스트

- 시스템 전체를 대상으로 테스트
- 성공 시 신뢰도는 매우 높음
- 하지만 범위가 크고 느리며 불안정(취성↑)해지기 쉬움
- 마이크로서비스 환경에서는 특히 수행 난이도 ↑

### 9.2.4 절충안

- 목표: 빠른 피드백과 시스템 신뢰 확보
- 단위 테스트: 빠르고 원인 파악 쉬움
- 서비스/엔드투엔드 테스트: 신뢰도 증가, but 속도 ↓ 비용 ↑
- 테스트 비율은 보통 → 단위 테스트 > 서비스 테스트 > 엔드투엔드 테스트
- 실행 시간이 너무 길면 큰 범위 테스트를 더 작은 단위 테스트로 대체 고려

## 9.3 서비스 테스트의 구현

- 서비스 테스트는 해당 마이크로서비스만 검증하며, 외부 협력 서비스는 제거(Stub 등으로 대체)
- 다운스트림 서비스 대신 스텁/목(Mock) 서비스와 연결해 테스트 수행

### 9.3.1 목 또는 스텁 사용

- 스텁(Stub)
    - 특정 요청에 대해 미리 정해진 응답 반환
    - 호출 횟수 등은 중요하지 않음
    - 단순하고 안정적
- 목(Mock)
    - 요청 발생 여부/횟수/파라미터까지 검증
    - 기대 호출이 없으면 테스트 실패
    - 과도하게 사용 시 테스트 취약해짐
- 서비스 테스트에서는 Stub을 더 많이 사용

### 9.3.2 더 영리한 스텁 서비스

- 직접 스텁 서버를 만드는 대신 재사용 가능한 스텁 서버 도구 활용 가능
- 대표 도구: 마운티뱅크(Mountebank)

## 9.4 까다로운 엔드투엔드 테스트의 구현

- 시스템 전체 기능을 검증하는 테스트로 여러 마이크로서비스를 함께 배포해야 수행 가능
- 장점: 전체 품질에 대한 높은 확신 제공
- 단점
    - 느림
    - 실패 원인 추적 어려움
    - 운영 환경과 버전 정합성 문제 발생 가능
- 여러 서비스 파이프라인을 공유된 엔드투엔드 단계로 팬인(Fan-in) 시키는 방식이 일반적

### 9.4.1 불안정하고 깨지기 쉬운 테스트

- 범위가 넓을수록: 참여 컴포넌트 ↑ → 실패 가능성 ↑, 네트워크 오류 등 외부 요인에 취약
- 비결정성 테스트 = 신뢰도 하락
    - 가끔 실패 → 다시 돌리면 통과
- 해결 원칙
    - 불안정 테스트는 최우선 제거/수정
    - 가능하면 더 작은 테스트로 대체

### 9.4.2 누가 엔드투엔드 테스트를 작성하는가?

- 기본 원칙은 해당 기능/서비스를 소유한 팀이 테스트 작성
- 문제 상황
    - 여러 팀이 무분별하게 추가 → 테스트 폭증
    - 소유권 불명확 → 실패 시 아무도 책임지지 않음
    - 테스트 전담팀이 운영하게 된다면, 개발팀과 테스트 단절되고 피드백 지연
- 시도된 해결책으로, 특정 테스트 세트를 특정 팀에 귀속
    - 그러나 다른 팀 변경이 테스트를 깨뜨릴 수 있음
- 결론
    - 공유 책임 모델은 유지 비용이 큼
    - 조직이 커질수록 팀 간 엔드투엔드 테스트는 한계 존재

### 9.4.3 엔드투엔드 테스트는 얼마나 오래 걸릴까?

- 실행 시간 매우 길어질 수 있음 (심하게는 며칠~수주)
- 문제: 불안정성 + 긴 수행시간 👎 → 결함 발견 시점이 너무 늦어짐
- 병렬화로 개선 가능 (예: Selenium Grid)
    - 하지만 테스트 정리·삭제는 필수
- 그래서 중복·저가치 테스트는 과감히 제거해야 함

### 9.4.4 대규모 적체

- 엔드투엔드 테스트가 오래 걸리면 실패 수정까지 시간이 지연되고 그 사이 변경 사항이 누적된다.
    - 빌드 적체 증가 → 배포 단위가 커짐 → 위험 증가
- 최악의 경우, 고장난 테스트 상태로도 체크인 진행됨
- 결론, 테스트 속도 개선이 최우선

### 9.4.5 메타버전

- 엔드투엔드 테스트 기준으로 여러 서비스를 묶어 하나의 버전으로 관리하려는 유혹 발생
- 👉 시스템 전체 버전 = 2.1.0
- 문제
    - 독립 배포 능력 상실
    - 서비스 간 결합 증가
    - 사실상 모놀리식 복귀

### 9.4.6 독립적인 테스트 가능성 부족

- 팀이 독립적으로 테스트/배포할 수 있는 구조가 중요

## 9.5 엔드투엔드 테스트를 피해야 할까?

- 소규모 서비스 수(소수 팀)에서는 여전히 유효
- 그러나 서비스/팀 수가 늘수록 → 테스트 시나리오 급증, 공유 테스트 집합 운영 어려움, 독립 배포 가능성 약화
- 구조적 중단(스키마 위반) → 명시적 스키마(예: JSON Schema 등) 로 충분히 탐지 가능
- 의미적 중단(동작 변경) → 스키마만으로는 탐지 불가하여 엔드투엔드 테스트가 감지 가능하지만 비용 큼
- 대안 필요: 의미적 중단만 효율적으로 잡아내는 테스트 → 계약 테스트 / 소비자 주도 계약(CDC)

### 9.5.1 계약 테스트와 소비자 주도 계약

- 계약 테스트란 소비자(업스트림)가 생산자(다운스트림) 서비스의 기대 동작을 테스트로 명시
    - 스텁/목 환경에서도 동일하게 통과해야 함
- CDC(Consumer-Driven Contract, 소비자 주도 계약)
    - 소비자가 기대 행동을 계약으로 정의하고 생산자가 자신의 빌드에서 이를 검증
    - 테스트 범위 = 생산자 서비스 1개 (외부 종속성 제거)
    - 빠르고 안정적이며 독립적 테스트 가능
    - 테스트 피라미드에서 서비스 테스트와 동일 계층
        
        <img width="553" height="372" alt="Image" src="https://github.com/user-attachments/assets/ad1b9ad5-fca0-4b79-acca-7d20db695b76" />
        

**📍 Pact (팩트)**

- 대표적인 CDC 도구
- 특징
    - 오픈소스
    - 다중 언어 지원(JVM/JS/Python/.NET 등)
    - HTTP + 메시징 지원
- 동작 방식
    - 소비자가 기대사항 정의 → Pact 파일 생성(JSON)
    - Pact 파일을 생산자가 가져가 검증 테스트 실행
    - Pact Broker 사용 시 → 계약 버전 관리, 검증 이력 관리, 서비스 의존 관계 시각화 가능
- 대안: Spring Cloud Contract (JVM 중심)

### 9.5.2 결론

- 서비스 수가 늘수록 엔드투엔드 테스트의 비용과 불안정성 증가
- 실무 경험 추세(선호) → CDC, 명시적 스키마, 운영 환경 내 테스트, 카나리아 릴리스
- 엔드투엔드 테스트는 보조 안전망으로는 여전히 유용하나 점차 비중이 줄어드는 추세
- 엔드투엔드 테스트 의존도 최소화하지만 무작정 제거는 금물

## 9.6 개발자 경험

- 실제 서비스들을 연결한 테스트 필요
    - 개발자가 로컬에서 실행해야 하는 마이크로서비스 수 증가
    - 로컬 성능·기술 스택 영향 큼 (JVM 등은 특히 리소스 부담↑)
- 해결 방안 1: 클라우드에서 개발/테스트 환경 실행
    - 장점: 더 많은 자원 활용 가능
    - 단점
        - 항상 네트워크 연결 필요
        - 코드 변경 → 업로드 과정에서 피드백 지연
        - 네트워크 품질에 영향 받음
        - 비용 증가
- 해결 방안 2: 완전 클라우드 IDE (AWS Cloud9)
    - 미래 가능성은 있지만 아직 일반적 현실은 아님
- 해결 방안 3: 가능하면 로컬에서 작업 중인 서비스만 실행 ⭐️
    - 스텁 활용

## 9.7 운영 전 테스트에서 운영 중 테스트로

- 기존 테스트는 운영 전 테스트로 품질 보장 시도했지만, 운영 환경에서는 예상 못한 상황 발생하기 때문에 모든 문제를 사전에 제거하는 것은 불가능
    - 분산 시스템은 너무 복잡하기 때문에 사전 테스트만으로는 리스크 0 불가
    - 테스트 투자 대비 효과는 일정 시점부터 감소
- 그래서 운영 환경에서 테스트하여, 더 높은 품질의 피드백 제공

### 9.7.1 운영 환경 테스트 유형

- 기본 상태 확인 (ping)
- 스모크 테스트
    - 배포 직후 실행
    - 정상 동작 여부 확인
    - 종종 릴리스 전 운영 환경에서 실행됨
- 카나리아 릴리스: 소수 사용자에게만 신규 버전 제공한 뒤 문제 없으면 점진 확대
- 가짜 사용자 동작 주입
    - 예: 가짜 주문 / 가짜 사용자 등록
    - 운영 환경을 실제로 검증
    - 단, 영향에 대한 우려 존재 → 안전 설계 필수

### 9.7.2 운영 환경에서 안전한 테스트 만들기

- 운영 테스트는 반드시 **안전하게 설계**
- 안전 예시
    - 상태 확인(ping)
    - 릴리스 전 단계의 스모크 테스트
    - 배포·릴리스 분리 시 더욱 안전
- 위험 테스트 예시: 가짜 사용자의 실제 액션 주입
- 결제/배송 등 실제 영향을 발생시키지 않도록 설계하고 데이터 오염 방지 필요

### 9.7.3 MTBF보다 MTTR?

- 운영 전 테스트만으로 모든 실패를 제거하는 것을 불가능하다 → 따라서 운영에서의 복구 능력(MTTR) 도 중요
    - MTBF = 평균 무고장 시간
    - MTTR = 평균 수리 시간
    - 두 가치 사이의 **균형 필요**

## 9.8 교차 기능 테스트

- 기존 테스트는 주로 기능 테스트 중심
    - 하지만 시스템에는 비기능(=교차 기능 요구 사항, CFR) 이 존재 (성능, 지연 시간, 처리량, 접근성, 보안)
- ‘비기능’보다는 CFR(Cross-Functional Requirements, 교차 기능 요구사항) 용어가 더 적절
    - 여러 서비스/기능이 함께 작동해야 충족됨
- 많은 CFR은 운영 환경에서만 의미 있게 판단 가능
- CFR 테스트 = 속성 테스트
- 서비스별로 CFR 목표가 다를 수 있음
    - 예: 결제 서비스 → 매우 높은 내구성 요구, 추천 서비스 → 상대적으로 낮아도 OK
- 이런 목표는 SLO(Service Level Objective, 팀의 서비스 수준 목표) 로 표현하는 것이 일반적
- CFR은 늦게 고민하면 위험, 가능한 일찍 정의하고 정기적 검토 필요

### 9.8.1 성능 테스트

- 성능 테스트는 대표적인 CFR 테스트
- 마이크로서비스 전환 시 성능 리스크 증가 → 네트워크 호출 증가, 호출 체인 길어짐, 일부 지연으로 인한 전체 영향 가능
- 핵심 흐름(E2E) 성능 테스트부터 시작
- 실행 방식
    - 사용자 수를 점차 증가시키며 수행
    - 지연 시간 변화 확인
- 테스트 환경은 가능하면 운영 환경과 유사해야 한다. (+ 데이터 양)
- 실행 주기: 체크인마다 수행은 비현실적이므로, 매일 혹은 매주
- 꼭 해야 할 것
    - 결과 반드시 확인해야 함
    - SLO 기준 정의 필요
        - 목표 응답 시간
        - 목표 처리량 등

### 9.8.2 견고성 테스트

- 마이크로서비스 시스템 신뢰성은 가장 약한 링크에 의해 결정됨
- 따라서 개별 서비스의 견고성(resilience) 강화 필요
- 일반적인 안정성 패턴 예 (자세한 내용은 12.5절 ‘안정성 패턴’)
    - 로드 밸런싱 + 다중 인스턴스
    - 회로 차단기(Circuit Breaker)
- 견고성 테스트 목적은 특정 결함이 발생해도 전체 시스템이 정상 동작 가능한지 확인하는 것
- 테스트 방법 예
    - 네트워크 타임아웃 인위적 주입
    - 다운스트림 장애 시나리오 재현
    - 장애 발생 후 복구 확인