## 12.1 회복 탄력성이란?

- David D. Woods의 4가지 핵심 관점
    - 견고성 (Robustness): 예상 가능한 변동을 흡수
    - 회복성 (Rebound): 충격 이후 얼마나 빨리 복구하는가
    - 원만한 확장성 (Graceful extensibility): 예상치 못한 상황에 어떻게 대응하는가
    - 지속적인 적응력 (Sustained adaptability): 변화하는 환경에 계속 적응하는 능력

### 12.1.1 견고성

- 예상 가능한 문제를 처리하도록 미리 설계하는 능력
- 마이크로서비스 환경의 대표적 변동: 호스트 장애, 네트워크 타임아웃, 서비스 비가용
- 대응 예시: 자동 재기동, 재시도, 적절한 오류 처리
- 견고성은 기술뿐 아니라 사람에게도 적용
    - 단일 담당자 리스크 ↑ → 백업 인력 필요
- 사전 지식 기반
    - 예측 가능한 문제에 대한 대비
    - 장애 발생 후 교훈을 반영해 강화 가능
- 하지만 견고성 향상 → 시스템 복잡도 증가

### 12.1.2 회복성

- 장애 이후 얼마나 잘 복구하는가
- 장애를 완전히 제거하는 것은 불가능하기 때문에 사전 준비 필요
    - 백업 (테스트 필수)
    - 장애 대응 플레이북
        - 대응 책임자, 사용자 노티 방식, 내부 커뮤니케이션 방식 등 포함
- 사전 합의된 대응 계획은 혼란과 스트레스 감소, 복구 속도 향상

### 12.1.3 원만한 확장성

- 견고성·회복성은 예상 가능한 상황 중심
- 예상하지 못한 상황에서는 시스템이 쉽게 붕괴
- 조직 구조 영향
    - 책임이 분산된 수평 조직 → 예기치 못한 상황에 강함
    - 경직된 규칙·권한 구조 → 대응력 저하
- 자동화의 양면성
    - 생산성 향상
    - 인력 축소 유도 → 돌발 상황 대응력 감소
- 핵심
    - 원만한 확장성은 기술보다 사람
    - 경험·권한·책임을 가진 인력이 필요

### 12.1.4 지속적인 적응력

- 대형 장애가 없었다 ≠ 안전하다
- 지속적인 적응력은 안주하지 않는 조직 문화에서 비롯됨
- 도구: 카오스 엔지니어링
- 조직 관점
    - 자율적인 소규모 팀 → 전체 그림을 놓칠 위험
    - 전역 최적화 vs 지역 최적화의 균형 필요
- 학습 문화
    - 비난 없는 환경
    - 장애 분석과 학습에 시간·자원 투자
- 핵심
    - 단기 성과 ↔ 장기 적응력의 균형
    - 지속적인 적응력은 전략이자 문화

### 12.1.5 그리고 마이크로서비스 아키텍처

- 마이크로서비스는 **견고성 향상에는 도움이 되지만** 회복 탄력성 전체를 보장하지는 않음
- 회복 탄력성의 본질 → 소프트웨어가 아니라 **사람과 조직의 속성**

## 12.2 장애는 어디에서나 발생한다

- 모든 시스템은 실패한다
    - 하드웨어 고장, 소프트웨어 버그, 네트워크 불신뢰
- 관점 전환
    - 실패를 막는 데만 집중 ❌
    - 실패를 원만하게 처리하는 데 집중 ✅
- 효과
    - 계획된 중단 > 계획되지 않은 중단
    - 무중단 배포 가능성 증가
- 사례: 구글
    - 서버 고장을 전제로 설계
    - 저렴한 하드웨어 + 빠른 복구
- 결론 ⇒ “실패는 발생한다”는 가정이 더 합리적인 아키텍처 선택으로 이어짐

## 12.3 얼마나 많아야 너무 많은 건가?

- 회복 탄력성 기술은 요구 사항에 따라 다름
- 과도한 설계는 낭비
- 핵심은 교차 기능 요구 사항 이해

**📌 주요 고려 요소**

- 응답 시간 / 지연 시간
    - 평균이 아닌 백분위수 기준
    - 동시 사용자 수 포함
- 가용성
    - 사용자에게 중요한 것은 “다운타임 수치”보다 “의존성”
- 데이터 내구성
    - 허용 가능한 데이터 손실 수준
    - 보관 기간 정책
- 요구 사항을 SLO(Service Level Objective)로 명확히 표현하는 것이 중요

## 12.4 기능 저하

- 마이크로서비스 환경에서는 부분 장애가 전체 장애로 이어질 위험
- 목표: 기능을 안전하게 저하시킬 수 있는 능력
- 예: 전자상거래
    - 재고 조회 불가 → 주문은 계속
    - 장바구니 장애 → UI 숨김 또는 대체 안내
- 모놀리식 → 정상 or 중단
- 마이크로서비스 → 기능별로 미묘한 상태 판단 필요
- 핵심 포인트 → 기술적 판단 ❌ 비즈니스 맥락 기반 판단 ⭕
- “이 서비스가 다운되면 무엇을 유지하고 무엇을 포기할 것인가?”
- 기능 중요도를 교차 기능 요구 사항과 함께 판단해야 함

## 12.5 안정성 패턴

- 목적: 부분 장애가 전체 장애로 확산되는 것을 방지
- 핵심 메시지
    - 느리게 실패하는 시스템은 빠르게 실패하는 시스템보다 훨씬 위험
    - 분산 시스템에서 지연 시간(latency)은 치명적
- 애드버트코프 사례 요약
    - 중요도가 낮은 다운스트림 서비스(순무 광고)가 느려짐
    - 잘못된 타임아웃·공유 커넥션 풀로 인해
        - 워커 스레드 고갈
        - 연쇄 장애 발생
        - 전체 사이트 다운
    - 교훈
        - 중요하지 않은 기능이 핵심 트래픽을 무너뜨릴 수 있음
        - 다운스트림 실패를 격리·차단·빠르게 실패시키지 않으면 위험

### 12.5.1 타임아웃

- 문제점
    - 타임아웃 없음 → 다운스트림 장애 시 전체 시스템 정지
    - 타임아웃 과도 → 시스템 전체 지연 + 리소스 고갈
- 다운스트림 응답 기대치 기반으로 타임아웃 설정
    - 호출 타임아웃: 1초
    - 커넥션 대기 타임아웃: 1초
- 중요한 개념
    - 단일 호출 타임아웃 ≠ 전체 작업 타임아웃
    - 전체 작업에 대한 타임아웃 예산(timeout budget) 필요
- 핵심 원칙
    - 모든 외부 호출에 기본 타임아웃 설정
    - 정상 응답 시간 기준으로 임계값 설정
    - 타임아웃 발생 시 반드시 기록·분석

### 12.5.2 재시도

- 재시도가 유효한 경우 = 일시적 오류
    - 네트워크 문제
    - 일시적 부하
- 재시도 판단 기준 → HTTP 예
    - ❌ 404 Not Found → 재시도 무의미
    - ⭕ 503, 504 → 재시도 가능
- 주의점
    - 무분별한 재시도는 부하를 악화시킴
    - 재시도 간 지연(backoff) 필요
- 재시도는 전체 타임아웃 예산 내에서만 허용
- 결론: 재시도는 강력하지만 타임아웃·백오프·예산과 함께 설계해야 함

### 12.5.3 벌크헤드 (Bulkhead)

- 개념: 선박의 격벽처럼 장애를 국소화
- 애드버트코프의 문제
    - 모든 다운스트림 호출이 하나의 커넥션 풀 공유
    - 하나의 느린 서비스가 전체 워커를 고갈
- 적용 방법
    - 다운스트림 서비스별 별도 커넥션 풀
    - 기능 단위로 서비스 분리
- 효과: 한 부분의 장애가 다른 부분에 전파되지 않음
- (추가 개념) 로드 셰딩(load shedding)
    - 시스템이 과부하 상태일 때 요청을 거부
    - 전체 붕괴 방지
- 벌크헤드는 타임아웃·회로 차단기보다 더 근본적인 보호 수단

### 12.5.4 회로 차단기 (Circuit Breaker)

- 목적: 실패 중인 다운스트림 호출을 자동으로 차단 → 빠르게 실패해 자원 낭비 방지
- 동작 방식
    - 실패/타임아웃이 임계값 초과 → 회로 열림(Open)
    - 열린 동안 요청은 즉시 실패
    - 일정 시간 후 일부 요청으로 상태 확인
    - 정상화되면 회로 닫힘
- 실패 판단 기준 예: 타임아웃, 5xx 응답
- 장점
    - 연쇄 장애 방지
    - 다운스트림 서비스 회복 기회 제공
- 애드버트코프 적용
    - 레거시 서비스별 회로 차단기 적용
    - 차단 시 해당 기능 비활성화, 나머지 사이트는 정상 제공
- 운영 시 수동 개폐 가능하도록 설계하는 것도 좋음
    - 유지보수 시 빠른 실패 유도
    - 배포 자동화에 활용 가능
- 핵심 원칙 → 느리게 실패 ❌ / 빠르게 실패 ⭕

### 12.5.5 격리

- 문제 인식: 서비스 간 의존성이 높을수록 장애 전파 위험 증가
- 논리적 격리
    - 서비스 간 직접 호출 제거
    - 버퍼링, 비동기 처리
- 물리적 격리: 동일 호스트, 동일 DB 인프라는 단일 장애 지점
- 예시
    - CPU를 독점하는 서비스 → 동일 호스트 서비스 모두 영향
    - 동일 DB 인프라 장애 → 여러 서비스 동시 장애
- 해결 방법
    - 독립된 VM / 컨테이너
    - 제한된 자원 할당
- 격리 ↑ → 비용·복잡성 ↑
    - 비용과 위험 사이의 균형 필요

### 12.5.6 이중화

- 개념: 단일 실패 지점을 제거하기 위한 **중복 구성**
- 적용 예
    - 여러 서비스 인스턴스 운영
    - 운영 지식의 이중화(사람)
- 클라우드 사례 (AWS)
    - 단일 EC2 인스턴스 가용성 보장 ❌
    - 단일 가용 영역 가용성 보장 ❌
    - → 여러 인스턴스 + 여러 AZ 필수
- 이중화는 장애 대응과 부하 처리 확장에도 기여
- 어디에 얼마나 필요한지는 장애 영향, 비용, 장애 가능성에 따라 결정

### 12.5.7 미들웨어

- 메시지 브로커의 장점
    - 전달 보장
    - 재시도·타임아웃 내장
- But, 모든 상황에 적합하지 않음
- 애드버트코프 사례
    - 요청/응답 구조에서는 큰 효과 없음
    - 오래된 요청이 큐에 쌓여 의미 없어질 수 있음
- 대안: 이벤트 기반 (브로드캐스트)

### 12.5.8 멱등성

- 정의: 여러 번 수행해도 결과가 변하지 않는 연산
- 중요성
    - 재시도
    - 메시지 재처리
    - 이벤트 중복 소비 대응
- 예: 주문 ID 기반 포인트 적립 → 동일 주문 → 한 번만 반영
- 이벤트 기반 시스템에서는 동일 이벤트를 여러 워커가 처리할 수 있기 때문에 멱등 처리 필수
- 주의점: 멱등성은 전체 시스템 상태가 아니라 비즈니스 연산 단위에서 고려해야 한다.
- HTTP 관련 오해
    - GET, PUT은 명세상 멱등
    - 실제 멱등성은 서버 구현에 달림
    - ⇒ 프로토콜이 멱등성을 보장해주지 않는다

## 12.6 위험 분산

- 핵심 개념: 모든 달걀을 한 바구니에 담지 말 것
- 문제 사례
    - 가상 호스트는 분리돼도 실제 물리 머신은 동일할 수 있음
    - 단일 SAN 장애 → 다수 VM 동시 장애
- 데이터 센터 분산
    - 단일 데이터 센터 의존 ❌
    - 다중 데이터 센터 / 리전 분산 ⭕
- AWS 사례
    - 리전 = 독립된 클라우드
    - 리전 내 다중 AZ 필수
    - 일부는 다중 리전 운영
- SLA vs 현실
    - 제공업체 SLA는 책임 제한 수단
    - SLA 충족 실패 시 실제 보상은 제한적
- 대응 전략
    - 플랜 B, C 준비
    - 다중 제공업체 활용
- 결론: 회복 탄력성은 기술 선택 + 배포 전략 + 계약 이해의 결과

## 12.7 CAP 정리

- 분산 시스템에서는 일관성(Consistency), 가용성(Availability), 단절내성(Partition Tolerance) 을 동시에 만족할 수 없음
- 장애(특히 네트워크 단절) 상황에서는 세 가지 중 최대 두 가지만 선택 가능
- CAP 정리는 이론이 아니라 분산 시스템 설계 시 반드시 마주치는 현실적인 절충(trade-off) 을 설명함
- 일관성(C): 어떤 노드에서 읽어도 동일한 결과
- 가용성(A): 모든 요청이 응답을 받음
- 단절내성(P): 네트워크 분리 상황에서도 시스템이 동작

### 12.7.1 일관성 희생 (AP 시스템)

- 네트워크 단절 시에도 서비스를 계속 제공 → 가용성 유지
- 노드 간 데이터 불일치 발생 가능 → 일관성 희생
- 복구 시점에 데이터 재동기화 필요 (단절이 길수록 어려움 증가)
- 대부분의 현실적인 분산 DB는 최종 일관성(Eventual Consistency) 을 선택

### 12.7.2 가용성 희생 (CP 시스템)

- 일관성을 유지하려면 노드 간 조율이 필요
- 네트워크 단절 시 조율 불가 → 요청 거부
- 결과적으로 가용성을 희생, CP 시스템
- 분산 환경에서 강한 일관성은 구현 난이도가 매우 높음
    - 분산 락, 트랜잭션 읽기 필요
    - 장애 시 락 해제 문제 발생 가능
- 직접 CP 시스템을 구현하지 말고, 검증된 저장소/락 서비스 사용 권장
    - 예: Consul 같은 강한 일관성 KV 저장소

### 12.7.3 단절내성 희생?

- 단절내성을 포기하면 분산 시스템 자체가 불가능
- 네트워크 없이 동작해야 하므로 단일 프로세스 시스템이 됨
- CA 시스템은 분산 시스템에서 존재할 수 없음

### 12.7.4 AP 아니면 CP?

- 정답은 없음 → 비즈니스 맥락에 따라 선택
- AP
    - 구축·확장 용이
    - 데이터 최신성이 다소 늦어도 허용되는 경우
- CP
    - 정확성이 절대적으로 중요한 경우 (예: 은행 잔고)
- CAP 정리는 무엇을 포기할지 묻는 질문을 던지게 해주는 도구

### 12.7.5 양자택일이 아니다

- 시스템 전체가 AP 또는 CP일 필요는 없음
- 서비스별, 기능별로 서로 다른 절충 가능
    - 예: 상품 카탈로그(AP), 재고(CP)
- 하나의 마이크로서비스 안에서도 기능별로 CAP 선택 가능
- Cassandra 같은 DB는 요청 단위로 일관성 수준 조절 가능

### 12.7.6 그리고 현실에서는

- 시스템은 현실 세계를 완벽히 반영할 수 없음
- 현실 세계에는 시스템 외부의 불확실성이 항상 존재
    - 예: 실제 재고 파손
- CP 시스템도 현실의 모든 오류를 막을 수는 없음
- 이런 이유로 현실 세계를 다루는 경우 AP 시스템이 합리적인 선택이 되는 경우가 많음

## 12.8 카오스 엔지니어링

- 실환경에서 격동적인 조건을 견뎌내는 시스템의 능력을 검증하는 실험
- 시스템이 실제 혼란을 견딜 수 있는지 실험을 통해 신뢰를 구축
- 단순한 도구 실행이 아니라 실험 문화
- 시스템은 소프트웨어 + 인프라 + 사람 + 프로세스 전체를 포함

### 12.8.1 게임 데이

- 사전에 계획되지만 참여자에게는 기습적인 훈련
- 사람과 프로세스의 준비 상태를 검증
- 대규모 장애·재해 상황까지 시뮬레이션 가능
- 특정 인물 의존성, 절차 문제 등을 드러내는 데 효과적

### 12.8.2 운영 환경의 실험

- 넷플릭스는 장애를 실제로 발생시켜 검증
- 대표 도구: Chaos Monkey
    - 무작위로 서버 종료
- 확장 도구들
    - Chaos Gorilla: AZ 단위 제거
    - Latency Monkey: 네트워크 지연 시뮬레이션
- 운영 환경에서 테스트해야 진짜 견고함을 확인 가능

### 12.8.3 견고성을 넘어

- 견고성: 예상된 문제를 견디는 능력
- 카오스 엔지니어링은 “만약 ~라면?” 질문을 지속적으로 던지는 도구
- 도구 자체보다 실험과 학습 문화가 핵심
- 도구 실행만으로 회복 탄력성이 생기지는 않음

## 12.9 비난

- 장애 이후 사람을 비난하는 문화는 학습을 막음
- 근본 원인 분석(RCA)가 사람을 원인으로 귀결되는 경우가 많음
- 비난 문화의 결과 → 문제 은폐, 동일한 장애 반복
- 중요한 것은
    - 비난 없는 회고
    - 실수를 안전하게 인정할 수 있는 환경
- 회복 탄력성의 핵심은 호기심과 학습 문화
- 장애는 처벌의 계기가 아니라 개선의 기회