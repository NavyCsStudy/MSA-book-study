## 5.1 이상적인 기술을 찾아서

### 5.1.1 하위 호환성을 쉽게  하라

어떤 기술을 선택하든 마이크로서비스를 변경할 때 해당 서비스를 소비하는 마이크로서비스와의 호환성이 깨지지 않도록 해야 한다.

### 5.1.2 인터페이스를 명시적으로 만들라

마이크로서비스 인터페이스는 명시적이어야 한다.

명시적 스키마는 마이크로서비스가 노출하는 인터페이스가 명시적이라는 것을 보장하는 데 큰 도움이 된다. (+ 지원 문서)

### 5.1.3 API를 기술 중립적으로 유지하라

마이크로서비스 간 통신에 사용된 API를 기술 중립적으로 유지하는 것이 중요하다.

다른 팀이나 서비스가 특정 기술을 강제로 써야만 하는 구조는 피해야 한다.

### 5.1.4 소비자를 위해 서비스를 단순하게 만들라

소비자가 마이크로서비스를 쉽게 사용할 수 있도록 만들라. → 비용, 기술 선택의 자유 등등

### 5.1.5 내부 구현 세부 사항을 숨겨라

소비자가 우리의 내부 구현에 종속되는 상황을 바라지 않는 것은 결합이 증가하기 때문이다.

마이크로서비스 내부에서 무언가를 변경하려는 경우 소비자에게도 변경을 요구해 소비자를 불편하게 만들 수 있다.

따라서 내부 표현의 상세 정보를 노출하도록 강요하는 기술은 피해야 한다.

## 5.2 기술 선택

### 5.2.1 원격 프로시저 호출

> RPC는 원격 서비스를 로컬처럼 호출하는 기술로, 명시적 스키마(IDL)를 통해 다양한 언어 간 통신을 가능하게 한다.
> 
> 
> 단, 스키마 공유와 관리가 필수다.
> 
- RPC(Remote Procedure Call)은 원격 서버의 함수를 로컬에서 호출하듯 실행할 수 있게 하는 기술이다.
- SOAP, gRPC 등은 명시적 스키마(Interface Definition Language, IDL) 를 필요로 한다.
    - SOAP의 경우 이 스키마를 WSDL(Web Services Description Language) 로 정의한다.
- 명시적 스키마를 사용하면 다양한 기술 스택에서 클라이언트 및 Stub 코드를 자동으로 생성할 수 있다.
- 즉, 클라이언트는 서비스 명세만 있으면 자체적으로 코드를 생성할 수 있어 별도의 공통 라이브러리 없이도 통신 가능하다.
- 다만, 클라이언트가 해당 스키마를 어디선가 확보할 방법이 필요하다는 제약이 있다.
- RPC 기술은 보통 직렬화 프로토콜을 포함하며, 데이터의 직렬화·역직렬화 방식을 프레임워크 수준에서 정의한다.

**문제점**

- 기술 결합
    - Java RMI처럼 특정 플랫폼이나 언어에 종속되는 RPC 구현이 있다.
    - 이는 내부 기술 세부 정보를 외부에 노출하는 형태가 될 수 있다.
    - 다만 gRPC, Thrift 등은 비교적 기술 중립적인 RPC 구현이다.
- 로컬 호출 ≠ 원격 호출
    - 네트워크 전송, 직렬화/역직렬화로 인한 성능 오버헤드가 있다.
    - 네트워크 장애, 지연, 패킷 손상 등 신뢰성 문제도 존재한다.
- 깨지기 쉬운 구조
    - 스키마(데이터 구조)가 바뀌면 역직렬화 과정에서 오류가 발생할 수 있다.
    - 오래된 필드는 쉽게 제거하지 못해 API가 점점 비대해지는 문제가 생긴다.

**적용 대상**

- 네트워크를 완전히 숨기지 말라.
    - RPC가 로컬 호출처럼 보이더라도, 실제로는 네트워크 호출임을 인지해야 한다.
    - 서버 인터페이스를 개선하더라도 클라이언트를 강제 업그레이드하지 않게 설계하라.
- gRPC의 활용 시점
    - 요청/응답이 명확하고, 클라이언트와 서버를 모두 제어할 수 있을 때 적합하다.
    - 동기식 호출뿐 아니라 스트리밍이나 반응형 통신에도 잘 어울린다.
- REST API로 대체가 더 나은 경우
    - 여러 언어나 플랫폼에서 접근해야 하거나  클라이언트가 서버 스키마를 컴파일할 수 없는 환경이라면 → HTTP 기반 REST API가 더 적절하다.

### 5.2.2 REST

- REST(Representational State Transfer)의 핵심은 리소스(Resource) 개념이다.
    - 리소스는 예를 들어 `Customer`처럼 서버가 관리하는 데이터 객체이다.
    - 서버는 요청에 따라 해당 리소스의 다양한 표현(Representation)을 생성해 반환한다.
- REST는 일반적으로 HTTP 프로토콜을 기반으로 구현된다.

**REST와 HTTP**

- HTTP는 REST 철학에 잘 맞는 여러 기능을 제공한다.
    - HTTP 메서드(GET, POST, PUT 등) 는 리소스 조작 방식에 대한 표준 동작을 정의한다.
        - `GET`: 리소스 조회 (멱등적)
        - `POST`: 리소스 생성
    - 예를 들어 `/customers` 엔드포인트는 고객 리소스를 다루며, 가능한 작업은 HTTP 메서드로 표현된다.
- HTTP는 풍부한 생태계를 갖추고 있다.
    - 캐싱(예: Varnish), 로드밸런싱(mod_proxy), 모니터링·보안 도구 등 다양한 인프라 지원.
    - 이를 통해 대규모 트래픽을 효율적이고 안정적으로 처리할 수 있다.

**HATEOAS (Hypermedia as the Engine of Application State)**

- HATEOAS는 REST의 핵심 제약 중 하나로 “클라이언트가 서버의 URI 구조를 미리 알지 않아도 된다”는 점이 핵심이다.
- 서버는 응답 본문에 하이퍼링크(링크 메타데이터) 를 포함해 클라이언트가 다음에 수행할 수 있는 동작을 링크 탐색을 통해 발견하도록 유도한다.

```json
{
  "id": 1,
  "name": "Alice",
  "email": "alice@example.com",
  "_links": {
    "self": { "href": "/customers/1" },
    "update": { "href": "/customers/1", "method": "PUT" },
    "orders": { "href": "/customers/1/orders" }
  }
}
```

- 클라이언트는 서버가 제공한 링크를 따라 다음 상태로 전이(transition) 하며 동작함
- 결과적으로 클라이언트-서버 간 결합도가 크게 낮아짐
- 이런 구조를 통해 API는 더 유연하고 진화 가능한 형태가 된다.

**문제점**

- 클라이언트 코드 생성의 어려움
    - 초기 REST는 명시적 스키마가 없어, 클라이언트 측 코드를 자동 생성하기 어려웠다.
    - 이 때문에 직접 클라이언트 라이브러리를 제공하는 경우가 많았고 결과적으로 서버-클라이언트 간 결합도가 높아졌다.
    - 최근에는 Swagger / OpenAPI 명세를 통해 다양한 언어의 클라이언트 코드를 자동 생성할 수 있게 되면서 이 문제가 완화되었다.
- 성능 한계
    - REST는 JSON 기반이라 SOAP보다 간결하지만 gRPC 등의 바이너리 프로토콜보다는 비효율적이다.
    - HTTP 요청마다 발생하는 네트워크 오버헤드로 인해 지연 시간이 중요한 환경에서는 부적합할 수 있다.
    - HTTP/3(QUIC 기반)은 이러한 성능 문제를 개선하기 위한 시도다.
    - HATEOAS를 사용할 경우 링크 탐색 과정에서 여러 번의 요청이 필요해 추가 round-trip 비용이 발생할 수 있다.
- 그럼에도 불구하고, REST는 여전히 서비스 간 통신의 기본 선택지로 널리 사용된다.

**적용 대상**

- 높은 상호운용성
    - REST는 대부분의 개발자가 익숙하고 언어·플랫폼 간 호환성이 좋아 외부 API나 공개 인터페이스에 적합하다.
- 효율적인 캐싱 구조
    - HTTP 캐싱 메커니즘을 활용해 대량의 요청을 효과적으로 처리할 수 있다.
- 적용 범위
    - REST는 마이크로서비스 간의 동기식 통신이나 외부 파트너 API 제공에 적합하다.
    - 다만, 고성능·저지연이 필요한 내부 통신에서는 gRPC 같은 바이너리 기반 프로토콜이 더 나을 수 있다.
- HATEOAS에 대한 견해
    - 일부 상황에서는 효과적일 수 있지만 모든 시스템에 반드시 필요한 것은 아니다.

### 5.2.3 GraphQL

- GraphQL은 클라이언트가 정확히 필요한 데이터만 요청할 수 있도록 설계된 쿼리 기반 API 규격이다.
- 이를 통해 클라이언트는 여러 REST 요청을 한 번의 쿼리로 대체할 수 있으며 특히 제한된 성능의 모바일·웹 환경에서 효율적인 데이터 조회가 가능하다.
- 예시: 고객의 최근 주문 내역을 표시하는 화면
    - REST 방식이라면 “고객 정보”와 “주문 내역”을 각각 다른 서비스에서 가져와야 한다.
    - GraphQL을 사용하면 **단일 쿼리로 필요한 데이터(최근 5건 + 고객 정보)**를 한 번에 가져올 수 있다.
- 이를 위해 마이크로서비스가 GraphQL 엔드포인트를 노출해야 한다.

**문제점**

- 서버 부하 증가 가능성
    - 클라이언트가 동적으로 다양한 쿼리를 날릴 수 있어 예측하기 어려운 복잡한 요청이 서버 리소스를 과도하게 소모할 수 있다.
- 성능 및 문제 추적 어려움
    - GraphQL에는 SQL처럼 쿼리 실행 계획이 없어 느린 쿼리나 비효율적인 요청을 분석하기 어렵다.
- 캐싱 복잡성
    - REST의 리소스 단위 캐싱(URI 기반)과 달리 GraphQL은 여러 리소스를 한 쿼리로 반환하므로 일반적인 HTTP 캐시를 적용하기 어렵다.
    - 해결책으로 각 리소스에 고유 ID 기반 캐싱 전략을 적용하기도 한다.
- 쓰기(Write) 작업의 비적합성
    - GraphQL은 이론적으로 쓰기를 지원하지만 실제로는 조회에 더 적합하다.
    - 따라서 일반적으로 읽기에는 GraphQL 쓰기는 REST를 함께 사용하는 하이브리드 접근이 많다.
- 비즈니스 로직과의 혼동
    - GraphQL은 데이터를 직접 다루는 느낌을 주지만 마이크로서비스는 단순한 데이터 래퍼가 아니라 고유한 도메인 로직을 가져야 한다.
    - 따라서 GraphQL API가 내부 DB와 직접 결합되지 않도록 주의해야 한다.

**적용 대상**

- 외부 클라이언트 인터페이스
    - 사용자 GUI(웹·앱)나 외부 개발자용 API 등 클라이언트가 다양한 데이터 조합을 요청하는 환경에 적합하다.
- API 호출 집계
    - 여러 하위 마이크로서비스에서 데이터를 조합해야 하는 경우 GraphQL은 호출을 집계·필터링하는 데 매우 유용하다.
- 대안 고려
    - GraphQL은 효과적인 솔루션이지만 복잡성이 높거나 내부 마이크로서비스 간 통신에는 BFF(Backend for Frontend) 패턴 같은 대안도 고려할 수 있다.

### 5.2.4 메시지 브로커

- 메시지 브로커는 마이크로서비스 간 통신을 중개하는 미들웨어이다.
- 서비스들은 직접 통신하지 않고, 메시지를 브로커에 전달해 비동기적으로 주고받는다.
- 메시지에는 요청 및 응답, 이벤트 등이 포함될 수 있다.

**토픽과 큐**

| 구분 | 큐 (Queue) | 토픽 (Topic) |
| --- | --- | --- |
| 통신 방식 | Point-to-Point (1:1) | Publish-Subscribe (1:N) |
| 수신자 | 하나의 소비자 그룹 내 한 인스턴스만 수신 | 구독한 모든 소비자 그룹이 각각 메시지 복사본 수신 |
| 용도 | 요청-응답 패턴에 적합 | 이벤트 기반 협업에 적합 |
| 발신자 인식 | 발신자가 수신자 존재를 앎 | 발신자는 누가 받을지 모름 (느슨한 결합) |
| 부하 분산 | O (큐 내부의 소비자 그룹 내 분산 처리) | 그룹 단위로 가능 (토픽-파티션 구조 활용) |
- 소비자는 하나 이상의 마이크로서비스로 표현되며 일반적으로 소비자 그룹으로 모델링된다.
    - 이는 여러 마이크로서비스 인스턴스가 있고 그중 하나가 메시지를 수신하길 원할 경우에 유용하다.
    - 메시지가 큐에 들어가면 소비자 그룹의 한 구성원만 해당 메시지를 받는다 → 부하 분산
- 토픽을 사용하면 여러 소비자 그룹을 가질 수 있다.
    
    <img width="1000" height="685" alt="Image" src="https://github.com/user-attachments/assets/4bbf9a6b-6b54-46d0-9000-349e1db19c17" />
    

**전달 보장**

- 브로커는 메시지를 소비자에게 성공적으로 전달할 때까지 보관한다. → 소비자가 일시적으로 다운돼도 메시지가 손실되지 않음.
- 이를 통해 업스트림 서비스는 신경 써야 할 실패 처리가 줄어든다.
- 신뢰성 확보를 위해 브로커는 보통 클러스터링 환경에서 실행되어 일부 노드 장애에도 메시지를 보존한다.
- 단, 전달 보장의 수준은 브로커마다 다르므로 정확히 이해하고 선택해야 한다.

**신뢰**

- 메시지의 안전한 전달을 위해서는 브로커 소프트웨어뿐 아니라 운영 환경(클러스터 설정, 복제, 장애 대응 등)도 신뢰할 수 있어야 한다.
- 즉, 기술적 신뢰 + 운영 신뢰가 모두 중요하다.
- 브로커를 얼마나 신뢰할 것인지 결정해야 한다.

**다른 특성**

- 메시지 순서 보장: 예를 들어 Kafka는 파티션 단위에서만 순서를 보장한다.
- 트랜잭션 지원: 일부 브로커는 메시지 쓰기에 대해 트랜잭션 기능을 제공한다.
- 정확히 한 번 전달(Exactly-once delivery):
    - 완벽하게 보장하기는 어렵지만, 메시지 ID를 통해 중복 처리를 방지할 수 있다.

**카프카**

- Kafka는 고성능 메시지 브로커이자 스트리밍 플랫폼이다.
- 특징:
    - 대용량 데이터 스트림 전송에 최적화 (배치 → 실시간 처리 전환 용이)
    - 여러 생산자·소비자 동시 지원
    - 메시지 영속성:
        - 소비 후에도 메시지를 삭제하지 않고 설정된 보관 기간(retention) 동안 유지 가능
        - 이를 통해 신규 소비자도 과거 메시지 재처리 가능
    - 스트림 프로세싱 내장:
        - 외부로 데이터를 내보내지 않고 Kafka 내부에서 실시간 처리 가능
        - `KSQL`을 통해 SQL 유사 문법으로 토픽 데이터를 처리
        - DB처럼 지속적으로 갱신되는 구체화 뷰(materialized view) 형태 구현 가능

## 5.3 직렬화 포맷

### 5.3.1 텍스트 포맷

- 사람이 읽기 쉽고 디버깅이 편하다.
- 다양한 언어와 플랫폼에서 쉽게 처리 가능해 상호 운용성이 높다.
- HTTP 기반 REST API에서 가장 널리 사용된다.
- JSON
    - 단순하고 가볍고 브라우저에 최적화
    - XML보다 간결하며, 사실상 표준으로 자리잡음
- XML
    - 구조적이고 하이퍼미디어 컨트롤 등 풍부한 표현 가능
    - 그러나 복잡하고 장황하여 현재는 잘 쓰이지 않음
- Avro (아브로)
    - JSON 기반이지만 스키마(schema)를 포함할 수 있는 포맷
    - 스키마 기반 직렬화를 지원해 구조화된 데이터 교환에 유용

### 5.3.2 바이너리 포맷

- 사람이 읽을 수 없지만, 전송 효율성과 처리 속도가 뛰어나다.
- 페이로드 크기 축소와 낮은 지연 시간이 필요한 환경에서 사용된다.
- 장점
    - 데이터 크기가 작아 네트워크 비용 절감
    - 직렬화/역직렬화 속도 빠름
    - CPU, 메모리 효율 향상

## 5.4 스키마

- 스키마(Schema) 는 데이터의 구조와 타입을 명시적으로 정의하는 규약이다.
- 직렬화 포맷에 따라 사용되는 스키마 기술이 다르다.
    - XML → XSD (XML Schema Definition)
    - JSON → JSON Schema
- 명시적 스키마는
    
    1️⃣ 서비스가 제공·수용하는 데이터 구조를 명확히 표현하고,
    
    2️⃣ 예상치 못한 변경으로 인한 엔드포인트 파손을 조기에 탐지하는 데 도움을 준다.
    

### 5.4.1 구조적 계약 위반 대 의미적 계약 위반

| 구분 | 설명 | 예시 |
| --- | --- | --- |
| **구조적 위반 (Structural Violation)** | 엔드포인트 구조 자체가 바뀌는 경우 | 필드나 메서드 제거, 필드명 변경, 새 필드 추가 |
| **의미적 위반 (Semantic Violation)** | 구조는 같지만 동작이나 의미가 바뀌는 경우 | 특정 필드의 의미나 값 해석 방식이 변경됨 |
- 구조적 위반은 스키마 비교로 탐지 가능 의미적 위반은 테스트로만 검증 가능

### 5.4.2 스키마를 사용해야 할까?

- 스키마를 사용하면 서로 다른 버전 간 구조적 불일치를 자동으로 감지할 수 있다.
- 스키마가 없으면, 이런 검증 책임이 전적으로 테스트 코드에 의존하게 된다.
- 특히 동적 타입 언어(JavaScript, Python 등) 에서는 컴파일러가 잡아주지 못하는 구조 오류를 테스트로 커버해야 한다.
- 명시적 스키마의 중요성
    - 문제는 “스키마를 사용하느냐”보다 “스키마를 명시적으로 정의하느냐” 이다.
    - 마이크로서비스가 **무엇을 노출할지/하지 않을지**를 명확히 하는 것이 중요하다.
    - 명시적 스키마는
        - 구조적 계약을 명확히 하고 팀 간 커뮤니케이션 비용을 줄이며, 안전망(safety net) 으로 작동한다.

## 5.5 마이크로서비스 간의 변경 처리

변화를 처리하는 방법은 실제로 두 가지 주제로 나뉜다.

- 중단 변경이 필요한 경우 어떻게 되는지
- 중단 변경을 피하기 위해 무엇을 할 수 있을지

## 5.6 중단 변경 피하기

- 중단 변경(Breaking Change) 이란 클라이언트가 기존 방식으로는 더 이상 서비스를 사용할 수 없게 만드는 변경이다.
- 마이크로서비스의 목표는 소비자(클라이언트)를 깨뜨리지 않고 점진적으로 발전하는 것이다.

### 5.6.1 확장 변경

- 기존 계약을 깨지 않고 확장하는 방식으로 변경한다.
- 즉, “새로운 것만 추가하고 기존 것은 제거하지 않는다.”
    - 새로운 필드 추가 ✅
    - 기존 필드 삭제 ❌
    - 응답 구조 변경 ❌

### 5.6.2 관대한 독자

- 클라이언트가 불필요하거나 모르는 필드는 무시하고 필요한 정보만 읽는 패턴.
- 서버가 새로운 필드를 추가해도 클라이언트는 깨지지 않는다.
- 이런 접근은 포스텔의 법칙(Postel’s Law) 과 관련 있다.
    
    > “보내는 건 엄격하게, 받는 건 관대하게.”
    > 
- 즉, 관대한 독자 패턴을 사용하면 하위 호환성 유지가 쉬워진다.

### 5.6.3 올바른 기술

- 일부 통신 기술은 인터페이스 변경에 더 취약하다.
- 기술 선택 자체가 변경의 유연성에 큰 영향을 준다.
    - 예: 스키마 기반 직렬화 기술(Avro, Protobuf)은 버전 호환성 검증이 용이
    - 반면 느슨한 REST JSON API는 호환성 관리가 상대적으로 어렵다

### 5.6.4 명시적 인터페이스

- 명시적 스키마를 사용하면 소비자가 무엇을 기대해야 하는지 명확히 알 수 있고 개발자도 어떤 변경이 위험한지 명확히 인지할 수 있다.
- RPC 기술은 오래전부터 명시적 스키마를 요구했지만 REST에서는 최근에야 OpenAPI, JSON Schema 등을 통해 이런 문화가 확산되고 있다.
- 비동기 메시징 분야에서도 AsyncAPI, CNCF 프로젝트 등으로 명시적 스키마 정의가 점점 늘어나고 있다.

### 5.6.5 우발적 중단 변경을 일찍 발견하기

- 아무리 조심해도 변경 과정에서 소비자를 깨뜨릴 가능성은 있다.
- 따라서 가능한 빨리 탐지하는 것이 중요하다.
- 방법
    1. 스키마 비교 도구 사용
        - 새 버전의 스키마를 기존 버전과 비교하여 하위 호환성 검증
        - 예: Confluent Schema Registry
            - JSON Schema, Avro, Protobuf 지원
            - 새 스키마 업로드 시 기존 스키마와 비교 → 호환성 위반 시 CI 빌드 실패
            - Kafka 생태계용이지만, Kafka 외의 통신 스키마도 검증 가능
    2. 테스트로 보완
        - 구조적 위반은 스키마 비교로 감지 가능하지만 의미적 위반은 여전히 테스트가 필요하다.
        - 스키마를 사용하지 않는 경우, 테스트가 중단 변경 탐지의 유일한 수단이 된다.

## 5.7 중단 변경 관리하기

### 5.7.1 락스텝 배포

- 락스텝 배포는 마이크로서비스와 소비자가 동시에 배포되어야 하는 방식이다.
- 이는 독립적 배포라는 마이크로서비스의 기본 철학과 상충한다.
- 인터페이스가 바뀔 때 소비자에게 업그레이드 시간을 주는 전략이 필요하다.

### 5.7.2 호환되지 않는 마이크로서비스 버전의 공존

<img width="916" height="903" alt="Image" src="https://github.com/user-attachments/assets/6e47193e-088e-47b1-bf63-5578722f18b0" />

- 구버전과 신버전 마이크로서비스를 동시에 운영하는 방식이다.
- 이전 소비자는 구버전으로, 새 소비자는 신버전으로 라우팅한다.
- 넷플릭스가 특정 상황에서 사용했지만 일반적으로는 권장되지 않는다.
    - 버그 수정 시 두 버전을 모두 관리해야 함
    - 트래픽 라우팅 로직이 복잡해짐
    - 데이터 및 상태 관리가 어렵고 추론이 복잡해짐

### 5.7.3 기존 인터페이스 에뮬레이션

<img width="833" height="484" alt="Image" src="https://github.com/user-attachments/assets/00d81d4e-2fee-4a6f-ab40-bf6d17b21478" />

- 한 서비스 내에서 신·구 인터페이스를 동시에 제공하는 방법이다.
- 신버전 배포 시 이전 인터페이스를 그대로 유지해, 소비자가 천천히 이전하도록 유도한다.
- 모든 소비자가 이전을 마치면 구 인터페이스를 제거한다.
- 단점은 여러 버전의 엔드포인트가 공존하면 테스트와 유지보수 비용이 급격히 증가한다는 점이다.
- 이를 완화하기 위해 내부적으로 요청을 신규 버전으로 변환(proxy) 하는 방식도 가능하다.
- REST API의 경우 `/v1/...`, `/v2/...` 식의 URI 버전이나 헤더 기반 버전으로 라우팅한다.
- RPC는 메서드 네임스페이스로 버전을 구분할 수 있지만, 타입 버전 호환은 여전히 어렵다.

### 5.7.4 어떤 방식을 선호하는가?

- 같은 팀이 서비스와 소비자를 모두 관리한다면 락스텝 배포도 한시적으로 허용 가능하다.
    - 하지만 반복적으로 락스텝을 수행하면 분산형 모놀리스로 퇴화한다.
- 버전 공존은 복잡하므로 짧은 기간에만 사용해야 하며, 블루-그린 배포나 카나리 배포처럼 단기 공존이 가능한 배포 전략과 잘 맞는다.
- 필자는 일반적으로 에뮬레이션 방식을 선호한다.
    - 여러 버전의 서비스를 공존시키는 것보다, 하나의 서비스에서 구버전을 흉내내는 것이 단순하기 때문이다.

### 5.7.5 사회적 계약

- 기술적 접근만큼이나 팀 간 합의(사회적 계약) 이 중요하다.
- 소비자와 서비스 팀 간 명확한 기준이 필요하다.
    - 인터페이스 변경은 어떻게 제안되는가?
    - 소비자와 서비스 팀은 어떻게 협의하는가?
    - 누가 소비자 코드를 업데이트하는가?
    - 소비자는 얼마나 빨리 새 인터페이스로 전환해야 하는가?
- 가능한 한 빨리 구 인터페이스를 종료해야 하지만 소비자가 전환할 수 있는 충분한 시간도 제공해야 한다.
- 소비자 변경이 불가능한 경우는 비용 대비 효과를 고려해 지원 종료 시점을 결정해야 한다.

### 5.7.6 사용성 추적

- 구 인터페이스 사용 중단 시점을 파악하려면 사용 추적이 필수다.
- 엔드포인트별로 로그를 남기거나, 소비자에게 클라이언트 식별자를 부여한다.
    - 예: HTTP의 user-agent, API Key, Gateway 식별 정보 등
- 어떤 소비자가 아직 구버전을 쓰는지 확인하면 전환 독려나 일정 조율이 훨씬 용이하다.

### 5.7.7 극단적 조치

- 모든 방법이 실패하고 소비자가 여전히 구버전을 사용한다면 극단적 조치가 필요할 수 있다.
- 한 대형 기업 사례:
    - 구 인터페이스 종료를 1년 전에 공지하고, 1년 후 예고 없이 종료
    - 중단된 소비자는 스스로 책임지는 구조
    - 하지만 사용 추적이 없어 너무 늦게 제거하는 비효율이 발생함
- 또 다른 사례:
    - 오래된 라이브러리 호출에 지연(sleep) 을 인위적으로 삽입해 느리게 동작하도록 함
    - 시간이 지날수록 지연을 늘려 소비자가 자연스럽게 새 버전으로 옮기도록 유도

## 5.8 마이크로서비스 세계에서 DRY와 코드 재사용의 위험

- DRY(Don’t Repeat Yourself)는 ‘반복하지 말라’는 의미로, 지식과 로직의 중복을 피하라는 조언이다.
- 동일한 코드가 여러 곳에 존재하면 시스템이 커지고 복잡해지며, 수정 시 누락·버그가 발생하기 쉽다.
- 그래서 일반적으로 DRY는 좋은 원칙이지만 마이크로서비스 환경에서는 함정이 될 수 있다.

### 5.8.1 라이브러리를 통한 코드 공유

- 여러 서비스가 동일한 라이브러리를 사용하면 그 라이브러리에 대한 의존성이 결합으로 발전할 수 있다.
    - 예를 들어, 핵심 도메인 객체를 공통 라이브러리로 관리할 경우 한 서비스의 변경이 모든 서비스 재배포로 이어질 수 있다.
- 또한 메시지 큐나 이벤트 스키마가 이 라이브러리에 의존할 경우 불일치나 누락으로 인한 장애가 발생하기 쉽다.
- 공통 로깅·모니터링처럼 외부에 노출되지 않는 내부 코드는 공유해도 괜찮다.
    - 하지만 도메인 로직이나 데이터 구조가 서비스 경계를 침범하는 형태의 공유는 결합을 유발한다.
- 어떤 조직은 이를 피하기 위해 “복사 후 수정” 전략을 사용한다. 즉, 공통 코드를 복제하되, 각 서비스가 독립적으로 관리하도록 한다.
- 동일한 라이브러리를 여러 서비스가 사용하더라도 일반적으로는 각 서비스에 포함된 버전을 배포한다.
    - 따라서 모든 서비스를 동시에 같은 버전으로 올리는 것은 거의 불가능하다.
    - 결국 여러 버전이 공존하게 되며 이를 감수할 수 있을 때만 라이브러리 재사용을 고려해야 한다.
- 반대로, 모든 사용자가 즉시 동일한 코드를 써야 한다면 별도 마이크로서비스로 기능을 분리하는 편이 낫다.

**클라이언트 라이브러리**

- 일부 팀은 서비스 접근성을 높이기 위해 클라이언트 라이브러리를 만든다.
    - 이는 중복 코드를 줄이지만, 잘못 설계하면 클라이언트에 서버 로직이 스며드는 문제가 생긴다.
- 클라이언트 라이브러리에 로직이 많아질수록 서비스 변경 시 모든 클라이언트를 수정해야 하는 상황이 발생한다.
- 또한 특정 기술 스택에 묶이게 되어 유연성을 잃는다.
- AWS
    - AWS는 서비스 호출을 직접 할 수도 있지만, 대부분은 SDK를 사용한다.
    - 이 SDK는 외부 커뮤니티나 AWS 내부의 별도 팀이 관리하며, 서비스와 느슨하게 분리되어 있다.
    - 클라이언트는 SDK 업그레이드 시점을 스스로 선택할 수 있으므로 독립적 배포가 가능하다.
    - 즉, 클라이언트 라이브러리를 사용하더라도 업그레이드 통제권은 소비자에게 있어야 한다.
- 넷플릭스 사례
    - 넷플릭스의 클라이언트 라이브러리는 단순히 코드 재사용 목적이 아니라, 안정성·복원력·로깅 등 시스템 품질 보장이 핵심 목적이다.
    - 하지만 시간이 지나며 클라이언트와 서버 간 결합이 증가해 업데이트 및 유지보수의 부담이 생겼다.
    - 이 사례는 클라이언트 라이브러리를 만들 때 서비스 로직과 전송 인프라 로직을 분리해야 함을 보여준다.

## 5.9 서비스 디스커버리

마이크로서비스가 많아질수록 각 서비스의 위치와 실행 상태를 파악해야 한다. 이를 해결하는 것이 서비스 디스커버리이다.

1. 인스턴스가 스스로 등록하고 “나 여기 있어요”라고 말하는 메커니즘 제공
2. 등록된 서비스를 찾는 방법을 제공

### 5.9.1 도메인 네임 시스템(DNS)

- DNS는 서비스 이름을 IP 주소로 매핑하는 가장 단순한 형태의 디스커버리 방식이다.
- 예를 들어 `accounts.musiccorp.net`이 항상 계정 마이크로서비스를 가리키게 설정할 수 있으며 로드 밸런서를 통해 여러 인스턴스로 트래픽을 분산시킬 수도 있다.
- 장점
    - 거의 모든 기술 스택이 지원하는 표준적이고 단순한 방식
    - 초기 도입이 쉽고 작은 규모에서는 충분히 효과적임
- 한계
    - TTL과 캐싱으로 인해 IP 변경이 즉시 반영되지 않음 → 클라이언트가 오래된 엔트리를 계속 사용할 수 있음
    - 자동화 및 동적 환경에서 비효율적 → 인스턴스가 자주 교체되는 경우 적합하지 않음
    - DNS 라운드로빈은 장애 노드를 식별하지 못해 트래픽을 중단시키기 어려움
- 개선 방안
    - 도메인 이름을 로드 밸런서로 연결해 인스턴스 추가·삭제를 관리
    - 환경별 도메인 템플릿 활용 (예: `accounts-dev.musiccorp.net`, `accounts-uat.musiccorp.net`)
    - AWS Route 53과 같은 관리형 DNS 서비스 활용 가능
    - 하지만 주기적인 엔트리 갱신이 필요한 환경에서는 동적 레지스트리가 더 적합하다.

### 5.9.2 동적 서비스 레지스트리

- DNS의 정적 한계를 극복하기 위해 등장한 방식
- 서비스 인스턴스가 실행 시 자신을 중앙 레지스트리에 등록하고 다른 서비스가 이를 조회하여 통신 대상을 찾는다.

**1️⃣ 주키퍼 (Zookeeper)**

- 원래 Hadoop 프로젝트의 일부로 개발된 분산 구성 저장소
- 계층적 네임스페이스를 제공하며 서비스 등록 정보나 설정값을 저장 가능
- 변경 감시(`watch`) 기능을 제공하여 서비스 변경 시 클라이언트에 알림 가능
- 하지만 서비스 디스커버리 용도로는 과도하게 복잡하며 현재는 더 적합한 대안(예: 콘술, etcd)이 많다.

**2️⃣ 콘술 (Consul)**

- 서비스 디스커버리 전용 솔루션으로 주키퍼보다 이 목적에 더 최적화됨
- 주요 특징:
    - DNS 및 HTTP API를 통해 서비스 조회 가능
    - SRV 레코드 지원으로 IP와 포트 정보를 함께 제공
    - 내장 Health Check 기능으로 인스턴스 상태 자동 감지
    - 키/값 저장소와 Consul Template을 통해 구성 파일 자동 업데이트
    - REST 기반 인터페이스로 다양한 기술 스택과 쉽게 통합 가능
- HAProxy 등 로드 밸런서 구성 자동화에 자주 사용됨
- 시크릿 관리 도구인 Vault와의 통합도 용이함

**3️⃣ etcd와 쿠버네티스 (Kubernetes)**

- 쿠버네티스는 자체 서비스 디스커버리 기능을 제공하며 내부적으로 etcd를 사용해 메타데이터와 구성을 관리한다.
    - `etcd`는 분산 시스템에서 구성 정보(configuration data)를 안전하게 저장하고, 여러 노드 간에 일관성을 유지하기 위한 키-값 저장소(Key-Value Store)
- 포드(Pod) 메타데이터 기반 패턴 매칭을 통해 자동으로 서비스 멤버를 식별하고 트래픽을 해당 포드 중 하나로 라우팅한다.
- 쿠버네티스 환경에서는 별도의 레지스트리 없이 내장 기능으로 충분하지만 다른 플랫폼과 혼합된 환경에서는 콘술 등 외부 도구 사용이 권장된다.

**4️⃣ 자체 구현 방식**

- 예전에는 AWS 태그를 기반으로 자체 디스커버리를 구현하기도 했다. → AWS API로 인스턴스를 쿼리해 서비스 목록을 조회
- 그러나 현재는 콘술, etcd, 쿠버네티스 등 상용 솔루션이 충분히 성숙했기 때문에 직접 구현하는 것은 “바퀴 재발명”에 불과하다.

### 5.9.3 사람이 사용한다는 것을 잊지 말자!

- 서비스 디스커버리는 자동화된 시스템 간 통신만이 목적이 아니다.
- 운영자나 개발자도 서비스의 위치와 상태를 이해하고 관리할 수 있어야 한다.
- 따라서 API나 관리 콘솔을 통해 사람이 쉽게 접근할 수 있는 인간 친화적 레지스트리를 제공하는 것이 바람직하다.

## 5.10 서비스 메시와 API 게이트웨이

| 구분 | 주요 위치 | 역할 | 대표 기능 |
| --- | --- | --- | --- |
| **API 게이트웨이** | 시스템 경계(외부 진입점) | 외부 요청을 내부 서비스로 라우팅 | 인증, 요청 제한, 로깅, 외부 접근 제어 |
| **서비스 메시** | 내부 네트워크(서비스 간) | 마이크로서비스 간 통신 관리 | 서비스 디스커버리, 로드밸런싱, 보안(mTLS), 트레이싱 |

### 5.10.1 API 게이트웨이

- 외부(남-북 방향) 트래픽을 내부 마이크로서비스로 라우팅하는 리버스 프록시 역할
    - 리버스 프록시란, 클라이언트 대신 서버 앞단에서 요청을 받아 실제 서버로 전달하고 응답을 다시 클라이언트에게 돌려주는 중간 서버
- 인증(API Key), 로깅, 속도 제한, 요청 집계 등 공통 기능을 중앙화
- 쿠버네티스 환경에서는 외부 접근을 위해 필수적

**적용 대상**

- 외부 클라이언트(웹, 모바일 앱)가 내부 서비스에 접근해야 할 때 사용
- 내부(동-서 방향) 통신에는 적합하지 않음
- 단순 리버스 프록시(예: Ambassador)부터 외부 고객용 상용 제품까지 다양
- 필요에 따라 게이트웨이를 분리(다중 게이트웨이 구성) 하여 복잡도를 관리

**회피 대상**

- 너무 많은 역할을 부여한 게이트웨이는 피해야 함
    - 호출 집계, 조건 로직, 프로토콜 변환(SOAP→REST 등) 같은 비즈니스 로직을 포함하지 말 것
- 게이트웨이는 단순히 요청을 전달하는 “얇은 파이프”로 유지해야 함.
- 게이트웨이에 로직이 쌓이면 변경이 중앙 집중화되어 릴리스 속도 저하, 팀 의존성 증가 초래
- 마이크로서비스 간 호출에 게이트웨이를 경유시키면 네트워크 홉 증가 → 성능 저하 발생
    
    → 내부 통신은 서비스 메시 사용이 더 적합함
    

### 5.10.2 서비스 메시

- 마이크로서비스 간(동-서 방향) 통신의 공통 기능을 네트워크 계층으로 분리
- 각 서비스 옆에 사이드카 프록시(보통 Envoy) 를 배치해 통신을 대리 처리
- 컨트롤 플레인이 전체 프록시 동작을 관리·모니터링함

**주요 기능**

- 서비스 디스커버리
- 로드 밸런싱
- 트래픽 라우팅 및 회로 차단
- 상호 TLS
- 트레이싱 및 로깅

**장점**

- 언어나 런타임에 상관없이 공통 기능을 통일 가능
- 라이브러리 업데이트 없이 통신 정책을 변경·배포 가능
- 조직 내 여러 팀 간의 표준화된 네트워크 표준 동작 제공

**주의점**

- “지능은 서비스에, 파이프는 단순하게” 원칙 유지 필요
    - 메시에는 비즈니스 로직을 넣지 말고, 공통 기술 기능만 위임
- 설정 복잡도가 높고 학습 곡선이 큼
- 소규모 시스템(서비스 5개 이하)에서는 오히려 과도한 선택일 수 있음
- 쿠버네티스 기반 환경에서 주로 사용하며 그렇지 않다면 도입 효과 제한적

**결론**

- 규모가 크고 다양한 언어로 작성된 마이크로서비스 환경에서는 서비스 메시가 큰 이점 제공
- 단, 도입 전 복잡도와 운영 부담을 충분히 검토해야 하며 API 게이트웨이와 서비스 메시는 역할을 명확히 구분해야 한다.

## 5.11 서비스 문서화

마이크로서비스로 세분화할수록 API의 수가 많아진다.

각 API가 무엇을 하는지, 어떻게 사용하는지를 알기 위해서는 문서화가 필수다.

이상적인 형태는

- 문서가 항상 최신 상태로 자동 유지되고,
- 서비스 엔드포인트와 연동되어 쉽게 접근 가능한 시스템이다.

### 5.11.1 명시적 스키마

- 명시적 스키마(OpenAPI)는 엔드포인트의 구조를 명확히 드러내 주지만 동작까지 설명하지는 못한다.
    
    → 따라서 좋은 설명 문서는 여전히 필요하다.
    
- 스키마가 없으면 더 많은 문서를 수동으로 작성해야 하며 문서가 실제 API와 불일치할 가능성도 높다.
- OpenAPI는 스키마 정의뿐 아니라 문서 포맷으로도 유용하다.
    
    → 다양한 오픈소스 포털(예: Ambassador Developer Portal)이 OpenAPI를 자동으로 읽어 문서 포털을 자동 생성할 수 있다.
    
- AsyncAPI와 CloudEvents는 이벤트 기반 인터페이스 문서화를 지원한다. → 최근에는 CloudEvents가 CNCF 지원과 다양한 통합으로 주목받고 있다.

### 5.11.2 자기 기술 시스템(Self-Describing Systems)

- 과거 SOA에서는 UDDI 같은 무거운 표준이 있었지만 실용적이지 않았다.
    
    → 대신 휴먼 레지스트리(Human Registry) 같은 가벼운 서비스 목록 시스템이 등장.
    
- 현대 시스템은 여러 도구를 조합해 서비스 상태를 파악한다.
    - 서비스 디스커버리(Consul, etcd): 실행 위치 확인
    - OpenAPI / CloudEvents: 기능과 엔드포인트 확인
    - 헬스 체크·모니터링: 상태 추적
    - 상관관계 ID: 호출 관계 파악
- 이 데이터들을 통합하면 실시간으로 시스템 전반을 이해할 수 있는 레지스트리를 만들 수 있다.
    
    → 정적 위키 대신 자동 수집·시각화된 대시보드로 발전 가능
    

> 명시적 스키마(OpenAPI 등)는 문서의 최신성과 일관성을 보장하고, 자기 기술 시스템(BizOps, Backstage 등)은 서비스를 자동으로 탐지·문서화해 대규모 마이크로서비스 환경을 이해하고 운영하기 쉽게 만든다.
>